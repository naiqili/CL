{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from playground.resnet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Lab\\CL\\playground\\resnet.py:37: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
      "  init.kaiming_normal(m.weight)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['state_dict', 'best_prec1'])\n",
      "ResNet(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): LambdaLayer()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): LambdaLayer()\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (shortcut): Sequential()\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "dataroot = 'D:\\Lab\\dataset'\n",
    "model_file = 'd:/Lab/models/resnet20.th'\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'\n",
    "b_size = 512\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "model = resnet20()\n",
    "model.to(device)\n",
    "checkpoint = torch.load(model_file)\n",
    "print(checkpoint.keys())\n",
    "new_state_dict = {}\n",
    "for k, v in checkpoint['state_dict'].items():\n",
    "    name = k[7:] # remove `module.`\n",
    "    new_state_dict[name] = v\n",
    "model.load_state_dict(new_state_dict)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([1, 64])\n",
      "[[0.96855986 0.8624826  0.86417043 0.27175245 0.44535327 0.41048002\n",
      "  0.98362535 0.6840507  0.70782393 1.0416753  0.7331234  0.8947437\n",
      "  0.30606967 0.7414024  0.424074   0.60355824 0.90790516 0.77997327\n",
      "  0.54325205 0.4578635  0.6942081  0.802485   0.80348504 0.8637515\n",
      "  0.30899972 0.7323786  0.6218271  0.5018098  0.5593489  0.7185232\n",
      "  0.45269474 0.5493137  0.75385785 0.6081369  0.59557515 0.74319595\n",
      "  0.75813335 1.0095528  0.71202767 0.8977708  0.88121134 0.91317374\n",
      "  0.82085615 0.60086274 0.7578388  0.64736825 0.6897727  0.9020686\n",
      "  0.86502063 1.0364416  0.80552065 0.793493   0.524859   0.9288619\n",
      "  0.8714397  0.86951077 0.87334824 0.75914764 0.73677003 0.83117115\n",
      "  0.23495193 0.98865163 0.5304062  0.47396272]]\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([1, 64])\n",
      "[[0.8840275  0.9788937  0.91436356 0.29684806 0.610125   0.38668227\n",
      "  0.9109282  0.76590985 0.7415572  1.102857   0.7998084  0.75293386\n",
      "  0.2341508  0.70141447 0.43168315 0.7461758  0.68468034 0.8399466\n",
      "  0.56534314 0.53346133 0.72442335 0.7668318  0.9448213  0.78548026\n",
      "  0.24887535 0.8818477  0.56955796 0.47560012 0.47573853 0.74371433\n",
      "  0.39522052 0.78519857 0.6275581  0.5709155  0.69223833 0.73804444\n",
      "  0.7490406  0.91742563 0.6364278  0.961813   0.7919828  1.0734675\n",
      "  0.7332554  0.61367667 0.79866517 0.6485387  0.63503075 0.9747926\n",
      "  0.7584595  0.84864336 0.9044988  0.89522535 0.5673345  0.9515961\n",
      "  0.8726847  0.9669542  0.88644713 0.80313903 0.7051565  0.7051449\n",
      "  0.25596392 0.98610485 0.53258586 0.5395437 ]]\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([1, 64])\n",
      "[[0.9343032  0.8560398  0.8072916  0.25074497 0.4427754  0.38589785\n",
      "  0.9488309  0.72798735 0.73554593 0.92432386 0.6815673  0.7407661\n",
      "  0.24826548 0.7204191  0.41595152 0.6848362  0.7289368  0.76295596\n",
      "  0.5570359  0.3981393  0.58205897 0.85908663 0.937332   0.71872437\n",
      "  0.33915797 0.75082463 0.5582772  0.547186   0.5473307  0.77190155\n",
      "  0.5544681  0.72237813 0.55339944 0.667971   0.6399418  0.7241284\n",
      "  0.7796664  0.9436329  0.70498437 0.8016106  0.9462346  1.0553769\n",
      "  0.884447   0.7620513  0.6725532  0.6456682  0.6032241  0.9406409\n",
      "  0.8310905  0.8936443  0.790375   0.8424719  0.5617722  0.9608815\n",
      "  0.934116   0.8392319  0.88479686 0.7008489  0.7632124  0.7603833\n",
      "  0.30299637 1.0087637  0.5468246  0.48164356]]\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([1, 64])\n",
      "[[0.952122   0.82140195 0.8862844  0.38627756 0.53772473 0.5503977\n",
      "  0.93082774 0.67514837 0.7073026  1.1312768  0.8244703  0.85776937\n",
      "  0.22622293 0.71599287 0.4631134  0.7110427  0.84457034 0.71544975\n",
      "  0.4880383  0.51821876 0.8000163  0.899421   0.7872092  0.7492449\n",
      "  0.23736343 0.8939891  0.5700353  0.54979676 0.5831375  0.86489135\n",
      "  0.37306356 0.53090835 0.6167953  0.66990024 0.6318413  0.8357768\n",
      "  0.8510859  0.80516857 0.718687   0.8254471  0.7836692  0.86290544\n",
      "  0.7709388  0.7225775  0.5488897  0.6423582  0.65810126 0.88436943\n",
      "  0.8068125  0.94886434 0.8848888  0.80919385 0.64210546 0.8918892\n",
      "  0.8532814  0.8996746  0.93674284 0.73884237 0.7509031  0.79428905\n",
      "  0.27312574 1.0184232  0.4638836  0.52386075]]\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([1, 64])\n",
      "[[0.9189175  0.8564434  0.8595466  0.3136602  0.46012664 0.4583848\n",
      "  0.9137214  0.87311846 0.7203757  1.0941479  0.8464004  0.88061535\n",
      "  0.29120693 0.78962207 0.51944524 0.6388799  0.79095787 0.7667741\n",
      "  0.4694369  0.4921228  0.7463951  0.7637499  0.81370157 0.680494\n",
      "  0.32867473 0.78480285 0.62399346 0.6423646  0.5994466  0.76627046\n",
      "  0.49485424 0.56541926 0.6318079  0.5689887  0.71241224 0.9435692\n",
      "  0.72521245 0.90248984 0.8316821  0.8555808  0.75906605 0.91238797\n",
      "  0.84895694 0.8095129  0.6489786  0.6960753  0.7180732  1.0003508\n",
      "  0.8364079  0.88925666 0.92978966 0.7698864  0.65318197 0.9084395\n",
      "  0.87186635 0.8565395  0.9129246  0.66427636 0.73534614 0.79287016\n",
      "  0.30243987 0.96322495 0.48703888 0.5665213 ]]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = torchvision.datasets.CIFAR10(root=dataroot, train=False, download=False, transform=transform)\n",
    "test_size = len(test_dataset)\n",
    "print(test_size)\n",
    "print()\n",
    "\n",
    "for k in range(5):\n",
    "    img, label = test_dataset[k]\n",
    "    print(img.shape)\n",
    "    model(img.unsqueeze(0))\n",
    "    print(model.feat.shape)\n",
    "    print(model.feat.detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 64)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "feat_dim = 64\n",
    "test_dataset = torchvision.datasets.CIFAR10(root=dataroot, train=False, download=False, transform=transform)\n",
    "test_size = len(test_dataset)\n",
    "\n",
    "test_feat_file = './tmp/test_feat.data'\n",
    "test_feat = np.zeros((test_size, feat_dim))\n",
    "print(test_feat.shape)\n",
    "\n",
    "for k in range(test_size):\n",
    "    img, label = test_dataset[k]\n",
    "    model(img.unsqueeze(0))\n",
    "    test_feat[k] = model.feat.detach().numpy()[0]\n",
    "    \n",
    "torch.save(test_feat, test_feat_file)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 64)\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "feat_dim = 64\n",
    "train_dataset = torchvision.datasets.CIFAR10(root=dataroot, train=True, download=False, transform=transform)\n",
    "train_size = len(train_dataset)\n",
    "\n",
    "train_feat_file = './tmp/train_feat.data'\n",
    "train_feat = np.zeros((train_size, feat_dim))\n",
    "print(train_feat.shape)\n",
    "\n",
    "for k in range(train_size):\n",
    "    img, label = train_dataset[k]\n",
    "    model(img.unsqueeze(0))\n",
    "    train_feat[k] = model.feat.detach().numpy()[0]\n",
    "    \n",
    "torch.save(train_feat, train_feat_file)\n",
    "print('Done!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
